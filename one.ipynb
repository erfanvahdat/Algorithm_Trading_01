{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from algorithm.module_list import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alaska Oil Spill Crews Seize on Calmer Weather...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PeopleSoft devotees in denial?</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blackhawks Re-Sign Defenseman Berard</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pakistani Militant Farooqi had Links With Top ...</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Schaub Rallies Falcons</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  category\n",
       "0  Alaska Oil Spill Crews Seize on Calmer Weather...  Sci/Tech\n",
       "1                     PeopleSoft devotees in denial?  Sci/Tech\n",
       "2               Blackhawks Re-Sign Defenseman Berard    Sports\n",
       "3  Pakistani Militant Farooqi had Links With Top ...     World\n",
       "4                             Schaub Rallies Falcons    Sports"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/GokuMohandas/Made-With-ML/main/datasets/news.csv\"\n",
    "\n",
    "df=pd.read_csv(url)\n",
    "df=df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\erfan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "STOPWORDS=stopwords.words('english')\n",
    "print(STOPWORDS[:5])\n",
    "porter=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'grete week nuse'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(text,stopwords=STOPWORDS):\n",
    "    text=text.lower()\n",
    "    pattern = re.compile(r\"\\b(\" + r\"|\".join(stopwords) + r\")\\b\\s*\")\n",
    "    text=pattern.sub('',text)\n",
    "    text=re.sub(r\"\\([^)]*\\)\", \"\", text)\n",
    "\n",
    "    \n",
    "    text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)  # separate punctuation tied to words\n",
    "    text = re.sub(\"[^A-Za-z0-9]+\", \" \", text)  # remove non alphanumeric chars\n",
    "    text = re.sub(\" +\", \" \", text)  # remove multiple spaces\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "text='Grete week for the NUSE!'\n",
    "preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to dataframe\n",
    "preprocessed_df = df.copy()\n",
    "preprocessed_df.title = preprocessed_df.title.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (84000,)\n",
      "X_test: (36000,)-> total-val: 120000\n",
      "y_train: (84000,)\n",
      "y_test: (36000,)\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "TRAIN_SIZE=0.7\n",
    "TEST_SIZE=0.3\n",
    "\n",
    "def Split(X,y):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,train_size=0.7)\n",
    "    return X_train,X_test,y_train,y_test\n",
    "\n",
    "X=preprocessed_df['title'].values\n",
    "y=preprocessed_df['category'].values\n",
    "\n",
    "X_train,X_test,y_train,y_test=Split(X,y)\n",
    "\n",
    "print(f\"X_train: {X_train.shape}\\n\"\n",
    "        f\"X_test: {X_test.shape}-> total-val: {len(preprocessed_df.title)}\\n\"\n",
    "        f\"y_train: {y_train.shape}\\n\"\n",
    "        f\"y_test: {y_test.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Label encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "CLASS_NUM=len(np.unique(y_train))\n",
    "label_encoding1=OneHotEncoder().fit(y_train.reshape(-1,1))\n",
    "label_encoding2=LabelEncoder().fit(y_train)\n",
    "\n",
    "CLASS_LIST=list(label_encoding2.classes_)\n",
    "y_train_enc=label_encoding2.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "del LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from candlestick import candlestick\n",
    "import pandas as pd\n",
    "path=f'cryptoData/'\n",
    "df=pd.read_csv(f'{path}ADA-USD.csv',parse_dates=True)\n",
    "# df['result']= candlestick.inverted_hammer(df)\n",
    "# print(df)\n",
    "z= candlestick.hammer(df,ohlc=[\"Open\", \"High\", \"Low\", \"Close\"],target='result')\n",
    "z\n",
    "# z['result_check']=z['result'].astype(\"category\").cat.codes\n",
    "# z = z[z['result_check'] != -1]\n",
    "\n",
    "# z['result'].value_counts()\n",
    "# z['result'].map(dict('True'=1, 'False'=0))\n",
    "# type(z['result'][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from candlestick import candlestick\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the Data\n",
    "path=f'cryptoData/'\n",
    "df=pd.read_csv(f'{path}SOL-USD.csv',parse_dates=True)\n",
    "\n",
    "# Result of the bearish_engulfing candle\n",
    "z= candlestick.dragonfly_doji(df,ohlc=[\"Open\", \"High\", \"Low\", \"Close\"],target='result')\n",
    "z['result_check']=z['result'].astype(\"category\").cat.codes\n",
    "z = z[z['result_check'] != -1]\n",
    "\n",
    "# Create the candlestick chart\n",
    "def plot(df,windows):\n",
    "\n",
    "    fig = go.Figure(data=[go.Candlestick(x=df.loc[:,'Date'],\n",
    "                  open=df.loc[:,'Open'], high=df.loc[:,'High'],low=df.loc[:,'Low'], close=df.loc[:,'Close'])])\n",
    "\n",
    "    # fig.add_trace(go.Scatter(x=z.loc[windows:,'Date'], y=z.loc[windows:,'result_check'], name=\"linear\",line_shape='linear'))\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=df.loc[windows:,'Date'], y=df.loc[windows:,'Close'],mode='markers',\n",
    "                        marker=dict(size=8, color=[ 'green' if i ==1  else 'red' for i in df.loc[windows:,'result_check']], showscale=True)))\n",
    "    \n",
    "    fig.update_layout(width=1500, height=600)\n",
    "    fig.update_layout(xaxis_rangeslider_visible=False)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# Show the chart\n",
    "# show all the postive signal\n",
    "b=z[z['result_check'] != 0]\n",
    "df=b\n",
    "plot(df,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=z[z['result_check']]\n",
    "\n",
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "# Load and preprocess the data\n",
    "path=f'cryptoData/'\n",
    "df=pd.read_csv(f'{path}ADA-USD.csv',parse_dates=True,index_col='Date')\n",
    "data_YY=df['Close'].shift(30)\n",
    "data_YY=torch.tensor(data_YY.fillna(data_YY.mean()))\n",
    "data_XX=torch.tensor(df.values)\n",
    "\n",
    "data =df.astype(float) # Convert the data to float type\n",
    "data = (df -df.mean()) / df.std() # Normalize the data\n",
    "data = torch.tensor(data.values).float() # Create a tensor from the data\n",
    "\n",
    "\n",
    "window_size = 30\n",
    "data_X = []\n",
    "data_y = []\n",
    "for i in range(len(data)-window_size):\n",
    "    data_X.append(data_XX[i:window_size+i])\n",
    "    data_y.append(data_YY[i:window_size+i])\n",
    "    \n",
    "\n",
    "data_X = torch.stack(data_X)\n",
    "data_y = torch.stack(data_y)\n",
    "\n",
    "\n",
    "\n",
    "# Define the model architecture\n",
    "class FinancialModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(FinancialModel, self).__init__()\n",
    "        # self.rnn = torch.nn.GRU(input_size, 64, num_layers=2, batch_first=True)\n",
    "        # self.fc = torch.nn.Linear(64, output_size)\n",
    "        self.fc = torch.nn.Linear(6, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 1)\n",
    "        # self.dropout = torch.nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x, _ = self.rnn(x)\n",
    "        # x = self.dropout(x[:, -1, :])\n",
    "        x = self.fc(x)\n",
    "        x=self.fc2(x)\n",
    "        return x\n",
    "\n",
    "X_train,X_test,y_train,y_test= split(data_X,data_y,test_size=0.2,shuffle=False)\n",
    "model = FinancialModel(input_size=X_train.shape[1], output_size=30)\n",
    "\n",
    "\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "train_loader=DataLoader(train_data,shuffle=False)\n",
    "\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Define the number of training iterations\n",
    "num_iterations = 40\n",
    "\n",
    "for iteration in range(num_iterations):\n",
    "    Loss=[]\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch.squeeze().float())\n",
    "    \n",
    "        # print(output.squeeze().shape)\n",
    "        # print(y_batch.abssqueeze().shape)\n",
    "        plt.ion()\n",
    "        loss = loss_fn(output.squeeze().float(), y_batch.squeeze().float())\n",
    "        Loss.append(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            plt.clf() # clear the plot\n",
    "            plt.plot(np.arange(len(Loss)), Loss,c='red')\n",
    "            plt.show()\n",
    "            plt.pause(0.001) # pause for a short time\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30, 6])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.42317942, 0.60885058]),\n",
       " 'hii',\n",
       " array([0.19092309, 0.31636793]),\n",
       " 'hii',\n",
       " array([0.53457839, 0.60410112]),\n",
       " 'hii']"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.choice([0, 1], size=10, p=[0.5, 0.5])\n",
    "X = np.random.rand(10)\n",
    "def counter():\n",
    "    a_plus=[]\n",
    "    box=[]\n",
    "    for index,z in enumerate(a):\n",
    "        if z ==1:  \n",
    "            box.append(0)\n",
    "            if len(box) <2:\n",
    "                first_index=index\n",
    "            \n",
    "            elif len(box) >1:                \n",
    "                last_index=index\n",
    "                box.clear()\n",
    "                a_plus.append(X[first_index:last_index+1])\n",
    "                a_plus.append('hii')\n",
    "    \n",
    "    return a_plus\n",
    "a_plus=counter()\n",
    "a_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0]),\n",
       " array([0.20614717, 0.79801224, 0.42317942, 0.60885058, 0.19092309,\n",
       "        0.31636793, 0.53457839, 0.60410112, 0.78405289, 0.04281032]))"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.92448713, 0.65885908, 0.59642019, 0.54274564, 0.39097281,],\n",
    "0.96784113, 0.93806501, 0.85367407, 0.19426317\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.random.choice([0.1,0.2], size=10, p=[0.6, 0.4])\n",
    "a = np.random.rand(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09ed3fb148af8040ef16323bd362106605fb927db47ce66d7fad9116314f36f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
