{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XGxDuzeMytz1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "welcome to project_1\n",
            " this is the Linear_Regression Porblem\n"
          ]
        }
      ],
      "source": [
        "print('welcome to project_1\\n',\n",
        "    'this is the Linear_Regression Porblem')\n",
        "#filtering through column in Df filter(regex='col')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eACNLO804654"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcsBF0Z4UsYj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from torch import nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\"\"\"- sigmoid and tanh at first layer is brilliant, but at last layer is\n",
        "         normal (tanh first layer only 99%, sigmoid first layer only 97%)\n",
        "                (tanh | sigmoid 93%)\n",
        "                (tan only first 99.8% brilliant)\n",
        "                (sigmoid only first 97.9% not bad)\n",
        "                (sigmoid  |  tanh 82%)\n",
        "                (relu  | sigmoid 97 %)\n",
        "                (relu | sigmoid 98% stable after only relu first)\n",
        "                (relu | tanh 95% not good compare to relu sigmoid,not stable)\n",
        "                (relu only is the best and stable)\n",
        "                (tanh is best After the relu)\n",
        "        - use two relu in order doesn't help much.only use at last layer 66%\n",
        "      \"\"\"\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "\"\"\"labeling\n",
        "1. list(np.unique(y))\n",
        "2. LabelEncoder.fit(y).classes or\n",
        "2_1. list(label_encoder.fit(y).classes_)\n",
        "\"\"\"\n",
        "label_encoder=LabelEncoder()\n",
        "ord=OrdinalEncoder()\n",
        "\n",
        "label_encoder_1=label_encoder.fit(y)\n",
        "ord_encoder=ord.fit(y.reshape(-1))\n",
        "\n",
        "classes=list(label_encoder_1.classes_)\n",
        "print(f'classes: {classes}')\n",
        "\n",
        "y_train_1=label_encoder.transform(y)\n",
        "y_train_ord=ord.transform(y.reshape(-1,1))\n",
        "y_train_ord_1=ord.fit_transform(y.reshape(-1,1))\n",
        "\n",
        "# y_train_1==y_train_ord.squeeze()\n",
        "# type(y_train_1),type(y_train_ord)\n",
        "print(f'\\n y[0]:  {y[0]}\\n y_train_1[0] :{y_train_1[0]}')\n",
        "\n",
        "# y_train_1.shape,y_train_ord.shape,y_train_ord_1.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoADWJHnUsgd"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "from sklearn.datasets import make_regression\n",
        "X_1,y_1=make_regression(n_samples=150, n_features=1, noise=1.5)\n",
        "X_1=torch.tensor(X_1,dtype=torch.float64)\n",
        "y_1=torch.tensor(y_1,dtype=torch.float64)\n",
        "# X=torch.squeeze(X)\n",
        "# y=torch.squeeze(y)\n",
        "# X.shape\n",
        "\n",
        "X_1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8urPgwSUUWU"
      },
      "outputs": [],
      "source": [
        "# X.shape,y.shape\n",
        "# np.vstack([X.numpy().squeeze(),y]).T\n",
        "# X.numpy().squeeze()\n",
        "\n",
        "plt.scatter(X,y,s=30,edgecolor='k')\n",
        "\n",
        "# X,y.reshape(-1,1)\n",
        "# y.reshape(-1,1).shape\n",
        "# a = np.array([1, 2, 3])\n",
        "# b = np.array([2, 3, 4])\n",
        "# np.vstack([a,b]).T\n",
        "# a.shape,X.numpy().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXUzy82QUsnI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfjVk7KFXnBT"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/GokuMohandas/Made-With-ML/main/datasets/spiral.csv\"\n",
        "url2='https://raw.githubusercontent.com/GokuMohandas/Made-With-ML/main/datasets/tumors.csv'\n",
        "\n",
        "df = pd.read_csv(url, header=0) # Load\n",
        "df_2=pd.read_csv(url2)\n",
        "df.head()\n",
        "X = df[[\"X1\", \"X2\"]].values\n",
        "y = df[\"color\"].values\n",
        "\n",
        "dict(collections.Counter(y))\n",
        "# label_encoder_1.classes_\n",
        "label=LabelEncoder().fit(y)\n",
        "label_y=label.transform(y.reshape(-1,1))\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "ord=StandardScaler().fit(X)\n",
        "ord_X=ord.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T88xDAjGiEFR"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "class_counts=dict(collections.Counter(y))\n",
        "class_counts_same=np.unique(class_counts)[0]\n",
        "print('one way:\\n{}\\n another way \\n {}'.format(class_counts,class_counts_same))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K12r0y-74eaS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CimSco36QFB"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "# Predictions\n",
        "\n",
        "pred_train = F.softmax(model_2(X_train), dim=1)\n",
        "pred_test = F.softmax(model_2(X_test), dim=1)\n",
        "\n",
        "pred_train = pred_train.max(dim=1)[1]\n",
        "pred_test = pred_test.max(dim=1)[1]\n",
        "\n",
        "train_acc=accuracy_score(y_train,pred_train)\n",
        "test_acc = accuracy_score(y_test, pred_test)\n",
        "print (f\"train acc: {train_acc:.2f}, test acc: {test_acc:.2f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsvaXXDY0VxN"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "def get_metrics(y_true, y_pred, classes):\n",
        "    \"\"\"Per-class performance metrics.\"\"\"\n",
        "    # Performance\n",
        "    performance = {\"overall\": {}, \"class\": {}}\n",
        "\n",
        "    # Overall performance\n",
        "    metrics = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "    performance[\"overall\"][\"precision\"] = metrics[0]\n",
        "    performance[\"overall\"][\"recall\"] = metrics[1]\n",
        "    performance[\"overall\"][\"f1\"] = metrics[2]\n",
        "    performance[\"overall\"][\"num_samples\"] = np.float64(len(y_true))\n",
        "\n",
        "    # Per-class performance\n",
        "    metrics = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
        "    \n",
        "    for i in range(len(classes)):\n",
        "        performance[\"class\"][classes[i]] = {\n",
        "            \"precision\": metrics[0][i],\n",
        "            \"recall\": metrics[1][i],\n",
        "            \"f1\": metrics[2][i],\n",
        "            \"num_samples\": np.float64(metrics[3][i]),\n",
        "        }\n",
        "\n",
        "    return performance\n",
        "# # Performance\n",
        "performance = get_metrics(y_true=y_test, y_pred=pred_test, classes=np.unique(y))\n",
        "print (json.dumps(performance, indent=2))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8E9gv8AlBx5"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81Ank4yDlB3u"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYEb3QlklB9d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raXjYNW_lCDn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcRVHeJYlCJY"
      },
      "source": [
        "âœ”\n",
        "\n",
        "-> **NOTE  ðŸ’¯**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7a7XaXBgHDf"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        " funciton of checking if X has enough dimention to build a stack matrix....\n",
        " when we have a extra one dimention squeeze can handle it and Removie it.and if\n",
        " has more than that. i would not Remove it.!!!!\n",
        "\"\"\"\n",
        "'''The same\n",
        "df['leukocyte_count'].mean(),np.mean(df.leukocyte_count)'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I03wY_wflCP-"
      },
      "source": [
        "##ðŸ”´Learning_note\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiFOiH_KG-iV"
      },
      "outputs": [],
      "source": [
        "\"\"\" Sorting the  name of the columns in  DF\n",
        "-> df.reindex(sorted(df.columns), axis=1)\n",
        "-> df.sort_index(axis=1)\n",
        "\n",
        "groupby of Never work in workclass column by sorting the ages\n",
        "\n",
        "-> aa=gkk.get_group('Never-worked').sort_values(by='age',ascending=True)\n",
        "-> aa.sort_values(by='age', ascending=True)\n",
        "\n",
        "uniqueness in one columns_ two way:\n",
        "-> class_counts=dict(collections.Counter(y))\n",
        "-> class_counts_same=np.unique(class_counts)[0]\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cYdUCOpbe4Z"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        " the problem of putting optimier inside a model is that when we reset the optmizer\n",
        " at every step, it will refer to the model to update it self. and when recall the\n",
        " model, itself is the model either and everytime it goes to update itself it will\n",
        " recall the previous change of optimzer and never change the gradient to decrese the \n",
        " \n",
        "  STD in pytohn\n",
        "-> np.std(X)\n",
        "-> X.std()\n",
        "----> hint:\n",
        "      never turn matrix to tensor before the Standards \n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPVb9qhFhoNn"
      },
      "outputs": [],
      "source": [
        "from bokeh.plotting import figure, show\n",
        "\n",
        "# prepare some data\n",
        "x = [1, 2, 3, 4, 5]\n",
        "y1 = [6, 7, 2, 4, 5]\n",
        "y2 = [2, 3, 4, 5, 6]\n",
        "y3 = [4, 5, 5, 7, 2]\n",
        "\n",
        "# create a new plot with a title and axis labels\n",
        "p = figure(plot_width=800,plot_height=300)\n",
        "\n",
        "# add multiple renderers\n",
        "p.line(x, y1, legend_label=\"Temp.\", color=\"blue\", line_width=2)\n",
        "p.line(x, y2, legend_label=\"Rate\", color=\"red\", line_width=2)\n",
        "p.line(x, y3, legend_label=\"Objects\", color=\"green\", line_width=2)\n",
        "\n",
        "# show the results\n",
        "show(p)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNXwhytta-oR"
      },
      "outputs": [],
      "source": [
        "p= figure(title='Simple line example',x_axis_label='x')\n",
        "p.line(x,y,legend_label='temp',line_width=2)\n",
        "show(p)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6MPqJAcff7o"
      },
      "outputs": [],
      "source": [
        "def func(a):\n",
        "    def wrap():\n",
        "        return ('i wrote ',a().lower())\n",
        "    return wrap # why cant use parenthesis here\n",
        "\n",
        "@func\n",
        "def say():\n",
        "    return 'hello'\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "say()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWzQ70JPfgC9"
      },
      "outputs": [],
      "source": [
        "def p():\n",
        "  # [i for i in global z,y]\n",
        "  global z,y\n",
        "  z=0\n",
        "  y=4\n",
        " \n",
        "  for i in range(3):\n",
        "    z+=i\n",
        "  return z\n",
        "\n",
        "ahmad=p()\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-Zma9IlfgIB"
      },
      "outputs": [],
      "source": [
        "z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3fgmVvAfgNg"
      },
      "outputs": [],
      "source": [
        "a=[1,5,3]\n",
        "b=[5,1,5]\n",
        "\n",
        "# list(zip(a,b))\n",
        "for i,b in enumerate(a):\n",
        "  # print(a[0],a[1],sep=' Fucker ')\n",
        "  print(i,b)\n",
        "  \n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIQ-tZfs_UQm"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "for i,don in enumerate(z):\n",
        "  # if don ==1:\n",
        "  #   continue\n",
        "  # else:\n",
        "  #   print(don)\n",
        "\n",
        "  if don==1 : continue\n",
        "  else:print(don)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJDZmEVF95AG"
      },
      "outputs": [],
      "source": [
        "b=dict(zip())\n",
        "c=set(zip())\n",
        "cc=list(zip())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iv2B69dfghP"
      },
      "outputs": [],
      "source": [
        "def outer_div(func):\n",
        "  def inner(z,r):  \n",
        "    if(z>r):  \n",
        "      z+=2\n",
        "    return func(z,r)\n",
        "  return inner  \n",
        "\n",
        "\n",
        "# syntax of generator  \n",
        "\n",
        "@outer_div\n",
        "def divide(z,r):\n",
        "     print(z+r)\n",
        "    \n",
        "\n",
        "a=divide(5,1)\n",
        "a\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "doszDQ07fgnp"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "a:\\env_python\\env\\lib\\site-packages\\gym\\envs\\classic_control\\cartpole.py:211: UserWarning: \u001b[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym(\"CartPole-v0\", render_mode=\"rgb_array\")\u001b[0m\n",
            "  gym.logger.warn(\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "from copy import deepcopy\n",
        "from joblib import Parallel, delayed\n",
        "from IPython.display import clear_output\n",
        "from IPython import display\n",
        "\n",
        "\n",
        "# tmp_env = gym.make(\"CartPole-v0\")\n",
        "\n",
        "# tmp_env.reset()\n",
        "# plt.imshow(tmp_env.render('rgb_array'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBIKt3JmUsyl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVhtI7bGUs97"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUy0z-vUUtEF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.0 ('env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "be3e1aef0b6a6b699858af168a8424076006b556f67ddfb8fc71b1ad292a96f8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
